{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cebd41b6",
   "metadata": {},
   "source": [
    "# SGD Mechanics & Attention Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f03531",
   "metadata": {},
   "source": [
    "## Part A - Manual SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3c7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/aaubs/ds-master/main/data/Swedish_Auto_Insurance_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc9f0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>392.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>46.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>422.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>119.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X      Y\n",
       "0  108  392.5\n",
       "1   19   46.2\n",
       "2   13   15.7\n",
       "3  124  422.2\n",
       "4   40  119.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92150279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample | w(old) | x | y_hat | dL/dw | w(new)\n",
      "------------------------------------------------\n",
      "1 | 0.500000 | 108 | 54.000000 | -73116.000000 | 7.811600\n",
      "2 | 7.811600 | 19 | 148.420400 | 3884.375200 | 7.423162\n",
      "3 | 7.423162 | 13 | 96.501112 | 2100.828918 | 7.213080\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (108, 392.5),\n",
    "    (19, 46.2),\n",
    "    (13, 15.7)\n",
    "]\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.0001     # learning rate\n",
    "w = 0.5            # initial weight\n",
    "\n",
    "print(\"Sample | w(old) | x | y_hat | dL/dw | w(new)\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "for i, (x, t) in enumerate(data, start=1):\n",
    "\n",
    "    # Forward pass\n",
    "    y_hat = x * w\n",
    "\n",
    "    # Loss\n",
    "    loss = (t - y_hat) ** 2\n",
    "\n",
    "    # Gradient\n",
    "    grad = 2 * x * (y_hat - t)\n",
    "\n",
    "    # Weight update\n",
    "    w_new = w - alpha * grad\n",
    "\n",
    "    print(f\"{i} | {w:.6f} | {x} | {y_hat:.6f} | {grad:.6f} | {w_new:.6f}\")\n",
    "\n",
    "    # Update weight for next sample (SGD!)\n",
    "    w = w_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28733b5f",
   "metadata": {},
   "source": [
    "## Part B - Attention Contextualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331de56",
   "metadata": {},
   "source": [
    "I choose to work with the following two sentences:\n",
    "\n",
    "Sentence 1: The police man gave me a fine\n",
    "\n",
    "Sentence 2: I am feeling fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e74d7dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ========== Embeddings (2D vectors) ==========\n",
    "\n",
    "embeddings = {\n",
    "    \"the\": np.array([0.1, 0.1]),\n",
    "    \"police\": np.array([0.9, 0.1]),\n",
    "    \"man\": np.array([0.6, 0.2]),\n",
    "    \"gave\": np.array([0.3, 0.3]),\n",
    "    \"me\": np.array([0.1, 0.2]),\n",
    "    \"a\": np.array([0.1, 0.1]),\n",
    "    \"fine\": np.array([0.5, 0.5]),\n",
    "\n",
    "    \"i\": np.array([0.1, 0.3]),\n",
    "    \"am\": np.array([0.2, 0.3]),\n",
    "    \"feeling\": np.array([0.1, 0.9]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5145f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "def self_attention(E):\n",
    "    # Q = K = V = E\n",
    "    scores = E @ E.T          # QK^T\n",
    "    A = softmax(scores)      # attention weights\n",
    "    context = A @ E          # new embeddings\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ebaa9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine embedding in sentence 1: [0.41482016 0.22562172]\n",
      "Fine embedding in sentence 2: [0.23577608 0.52729733]\n"
     ]
    }
   ],
   "source": [
    "# Sentence 1 tokens\n",
    "sentence1 = [\"the\", \"police\", \"man\", \"gave\", \"me\", \"a\", \"fine\"]\n",
    "\n",
    "E1 = np.array([embeddings[word] for word in sentence1])\n",
    "\n",
    "context1 = self_attention(E1)\n",
    "\n",
    "# Find new embedding for \"fine\" in sentence 1\n",
    "fine_index_1 = sentence1.index(\"fine\")\n",
    "fine_context_1 = context1[fine_index_1]\n",
    "\n",
    "print(\"Fine embedding in sentence 1:\", fine_context_1)\n",
    "\n",
    "\n",
    "# Sentence 2 tokens\n",
    "sentence2 = [\"i\", \"am\", \"feeling\", \"fine\"]\n",
    "\n",
    "E2 = np.array([embeddings[word] for word in sentence2])\n",
    "\n",
    "context2 = self_attention(E2)\n",
    "\n",
    "# Find new embedding for \"fine\" in sentence 2\n",
    "fine_index_2 = sentence2.index(\"fine\")\n",
    "fine_context_2 = context2[fine_index_2]\n",
    "\n",
    "print(\"Fine embedding in sentence 2:\", fine_context_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0b5f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine similarity between the two 'fine' embeddings: 0.7947668623453286\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "similarity = cosine_similarity(fine_context_1, fine_context_2)\n",
    "\n",
    "print(\"\\nCosine similarity between the two 'fine' embeddings:\", similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
